{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a spark context\n",
    "hc = (SparkSession.builder\n",
    "                  .appName('Toxic Comment Classification')\n",
    "                  .enableHiveSupport()\n",
    "                  .config(\"spark.executor.memory\", \"4G\")\n",
    "                  .config(\"spark.driver.memory\",\"18G\")\n",
    "                  .config(\"spark.executor.cores\",\"7\")\n",
    "                  .config(\"spark.python.worker.memory\",\"4G\")\n",
    "                  .config(\"spark.driver.maxResultSize\",\"0\")\n",
    "                  .config(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "                  .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n",
    "                  .config(\"spark.default.parallelism\",\"2\")\n",
    "                  .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc.sparkContext.setLogLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_spark_df(fin):\n",
    "    \"\"\"\n",
    "    Parse a filepath to a spark dataframe using the pandas api.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fin : str\n",
    "        The path to the file on the local filesystem that contains the csv data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pyspark.sql.dataframe.DataFrame\n",
    "        A spark DataFrame containing the parsed csv data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fin)\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    df = hc.createDataFrame(df)\n",
    "    return(df)\n",
    "\n",
    "# Load the train-test sets\n",
    "train = to_spark_df(\"/Users/dayti/kaggle/Toxic Comment/train.csv\")\n",
    "test = to_spark_df(\"/Users/dayti/kaggle/Toxic Comment/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = [i for i in train.columns if i not in [\"id\", \"comment_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|0000997932d777bf|Explanation\n",
      "Why t...|    0|           0|      0|     0|     0|            0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|0002bcb3da6cb337|COCKSUCKER BEFORE...|    1|           1|      1|     0|     1|            0|\n",
      "|0005c987bdfc9d4b|Hey... what is it...|    1|           0|      0|     0|     0|            0|\n",
      "|0007e25b2121310b|Bye! \n",
      "\n",
      "Don't look...|    1|           0|      0|     0|     0|            0|\n",
      "|001810bf8c45bf5f|You are gay or an...|    1|           0|      1|     0|     1|            1|\n",
      "|00190820581d90ce|FUCK YOUR FILTHY ...|    1|           0|      1|     0|     1|            0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.filter(F.col('toxic') == 1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic sentence tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(train)\n",
    "\n",
    "# Count the words in a document\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "tf = hashingTF.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rawFeatures=SparseVector(262144, {19208: 1.0, 23032: 1.0, 24417: 1.0, 25000: 1.0, 29945: 1.0, 32241: 1.0, 32976: 1.0, 37852: 1.0, 46075: 1.0, 59853: 1.0, 72125: 1.0, 77971: 1.0, 81631: 1.0, 82999: 1.0, 83922: 1.0, 91677: 1.0, 97171: 1.0, 100258: 1.0, 101169: 1.0, 103838: 3.0, 110427: 1.0, 113031: 1.0, 113418: 1.0, 135568: 1.0, 139533: 1.0, 140784: 1.0, 145284: 1.0, 151536: 1.0, 164148: 1.0, 169364: 1.0, 176964: 1.0, 182267: 1.0, 192137: 1.0, 193131: 1.0, 229137: 1.0, 230921: 1.0, 231630: 1.0, 244466: 1.0, 246621: 1.0, 249835: 1.0, 253170: 1.0})),\n",
       " Row(rawFeatures=SparseVector(262144, {17429: 1.0, 38728: 1.0, 83815: 1.0, 88337: 1.0, 101527: 1.0, 101833: 1.0, 108541: 1.0, 125765: 1.0, 141219: 1.0, 151980: 1.0, 169364: 1.0, 169800: 1.0, 203235: 1.0, 208090: 1.0, 219140: 1.0, 242101: 1.0, 248135: 1.0, 249180: 1.0}))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.select('rawFeatures').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the idf model and transform the original token frequencies into their tf-idf counterparts\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(tf) \n",
    "tfidf = idfModel.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(262144, {19208: 2.244, 23032: 5.0123, 24417: 0.7386, 25000: 5.6813, 29945: 3.0517, 32241: 8.3967, 32976: 5.0285, 37852: 1.7539, 46075: 6.9564, 59853: 3.1525, 72125: 2.2744, 77971: 7.6108, 81631: 3.4198, 82999: 7.5735, 83922: 6.4588, 91677: 0.6965, 97171: 2.0163, 100258: 1.1947, 101169: 1.734, 103838: 1.2127, 110427: 2.1173, 113031: 8.9845, 113418: 2.2023, 135568: 3.5864, 139533: 2.5136, 140784: 3.0483, 145284: 7.6628, 151536: 2.2412, 164148: 6.0064, 169364: 2.4772, 176964: 1.7656, 182267: 8.613, 192137: 3.1018, 193131: 5.6703, 229137: 4.5705, 230921: 2.0429, 231630: 8.2914, 244466: 3.351, 246621: 10.0343, 249835: 6.827, 253170: 2.7021}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.select(\"features\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG = 0.1\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol='toxic', regParam=REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|               words|         rawFeatures|            features|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n",
      "|0000997932d777bf|Explanation\n",
      "Why t...|    0|           0|      0|     0|     0|            0|[explanation, why...|(262144,[19208,23...|(262144,[19208,23...|\n",
      "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|[d'aww!, he, matc...|(262144,[17429,38...|(262144,[17429,38...|\n",
      "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|[hey, man,, i'm, ...|(262144,[14,9639,...|(262144,[14,9639,...|\n",
      "|0001b41b1c6bb37e|\"\n",
      "More\n",
      "I can't ma...|    0|           0|      0|     0|     0|            0|[\", more, i, can'...|(262144,[4081,517...|(262144,[4081,517...|\n",
      "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|[you,, sir,, are,...|(262144,[37852,39...|(262144,[37852,39...|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(tfidf.limit(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train = lrModel.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+--------------------+----------+\n",
      "|              id|toxic|         probability|prediction|\n",
      "+----------------+-----+--------------------+----------+\n",
      "|0000997932d777bf|    0|[0.98581646633835...|       0.0|\n",
      "|000103f0d9cfb60f|    0|[0.98344821303795...|       0.0|\n",
      "|000113f07ec002fd|    0|[0.95500173136246...|       0.0|\n",
      "|0001b41b1c6bb37e|    0|[0.99453009308165...|       0.0|\n",
      "|0001d958c54c6e35|    0|[0.96269618805532...|       0.0|\n",
      "|00025465d4725e87|    0|[0.95766822132553...|       0.0|\n",
      "|0002bcb3da6cb337|    1|[0.27147906115805...|       1.0|\n",
      "|00031b1e95af7921|    0|[0.96287942446786...|       0.0|\n",
      "|00037261f536c51d|    0|[0.98502026615636...|       0.0|\n",
      "|00040093b2687caa|    0|[0.96974700476352...|       0.0|\n",
      "|0005300084f90edc|    0|[0.99999214813733...|       0.0|\n",
      "|00054a5e18b50dd4|    0|[0.96909930941050...|       0.0|\n",
      "|0005c987bdfc9d4b|    1|[0.04657011154294...|       1.0|\n",
      "|0006f16e4e9f292e|    0|[0.99600536691196...|       0.0|\n",
      "|00070ef96486d6f9|    0|[0.98042892897313...|       0.0|\n",
      "|00078f8ce7eb276d|    0|[0.99157617779791...|       0.0|\n",
      "|0007e25b2121310b|    1|[0.20164110039400...|       1.0|\n",
      "|000897889268bc93|    0|[0.97616369741436...|       0.0|\n",
      "|0009801bd85e5806|    0|[0.98010032569437...|       0.0|\n",
      "|0009eaea3325de8c|    0|[0.98840835604315...|       0.0|\n",
      "+----------------+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_train.select(\"id\", \"toxic\", \"probability\", \"prediction\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|               words|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|0000997932d777bf|Explanation\n",
      "Why t...|    0|           0|      0|     0|     0|            0|[explanation, why...|(262144,[19208,23...|(262144,[19208,23...|[4.24138850720369...|[0.98581646633835...|       0.0|\n",
      "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|[d'aww!, he, matc...|(262144,[17429,38...|(262144,[17429,38...|[4.08457091112856...|[0.98344821303795...|       0.0|\n",
      "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|[hey, man,, i'm, ...|(262144,[14,9639,...|(262144,[14,9639,...|[3.05508913911535...|[0.95500173136246...|       0.0|\n",
      "|0001b41b1c6bb37e|\"\n",
      "More\n",
      "I can't ma...|    0|           0|      0|     0|     0|            0|[\", more, i, can'...|(262144,[4081,517...|(262144,[4081,517...|[5.20300875781151...|[0.99453009308165...|       0.0|\n",
      "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|[you,, sir,, are,...|(262144,[37852,39...|(262144,[37852,39...|[3.25064235880067...|[0.96269618805532...|       0.0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select second element in each row of the column vector\n",
    "extract_prob = F.udf(lambda x: float(x[1]), T.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|      proba|prediction|\n",
      "+-----------+----------+\n",
      "|0.014183533|       0.0|\n",
      "|0.016551787|       0.0|\n",
      "| 0.04499827|       0.0|\n",
      "|0.005469907|       0.0|\n",
      "|0.037303813|       0.0|\n",
      "|0.042331778|       0.0|\n",
      "| 0.72852093|       1.0|\n",
      "|0.037120577|       0.0|\n",
      "|0.014979734|       0.0|\n",
      "|0.030252995|       0.0|\n",
      "|7.851862E-6|       0.0|\n",
      "| 0.03090069|       0.0|\n",
      "|  0.9534299|       1.0|\n",
      "|0.003994633|       0.0|\n",
      "|0.019571071|       0.0|\n",
      "|0.008423822|       0.0|\n",
      "|  0.7983589|       1.0|\n",
      "|0.023836304|       0.0|\n",
      "|0.019899674|       0.0|\n",
      "|0.011591644|       0.0|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(res_train.withColumn(\"proba\", extract_prob(\"probability\"))\n",
    " .select(\"proba\", \"prediction\")\n",
    " .show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Results Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert test text\n",
    "test_tokens = tokenizer.transform(test)\n",
    "test_tf = hashingTF.transform(test_tokens)\n",
    "test_tfidf = idfModel.transform(test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='00001cee341fdb12')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize the new DataFrame with the id column\n",
    "test_res = test.select('id')\n",
    "test_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "...fitting\n",
      "...predicting\n",
      "...appending result\n",
      "...extracting probability\n",
      "+----------------+------------+\n",
      "|              id|       toxic|\n",
      "+----------------+------------+\n",
      "|000968ce11f5ee34|  0.04655437|\n",
      "|00491682330fdd1d|3.6486778E-8|\n",
      "|008eb47c4684d190|   0.6308229|\n",
      "|00d251f47486b6d2|  0.06102414|\n",
      "|0114ae82c53101a9|  0.43038085|\n",
      "+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "severe_toxic\n",
      "...fitting\n",
      "...predicting\n",
      "...appending result\n",
      "...extracting probability\n"
     ]
    }
   ],
   "source": [
    "#Make predictions for each class\n",
    "test_probs = []\n",
    "for col in out_cols:\n",
    "    print(col)\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=col, regParam=REG)\n",
    "    print(\"...fitting\")\n",
    "    lrModel = lr.fit(tfidf)\n",
    "    print(\"...predicting\")\n",
    "    res = lrModel.transform(test_tfidf)\n",
    "    print(\"...appending result\")\n",
    "    test_res = test_res.join(res.select('id', 'probability'), on=\"id\")\n",
    "    print(\"...extracting probability\")\n",
    "    test_res = test_res.withColumn(col, extract_prob('probability')).drop(\"probability\")\n",
    "    test_res.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
